P versus NP

P versus NP is the following question of interest to people working with computers and in mathematics: Can every solved problem whose answer can be checked quickly by a computer also be quickly solved by a computer? P and NP are the two types of maths problems referred to: P problems are fast for computers to solve, and so are considered "easy". NP problems are fast (and so "easy") for a computer to check, but are not necessarily easy to solve. 

In 1956, Kurt Gödel wrote a letter to John von Neumann. In this letter, Gödel asked whether a certain NP complete problem could be solved in quadratic or linear time. In 1971, Stephen Cook introduced the precise statement of the P versus NP problem in his article "The complexity of theorem proving procedures". 

Today, many people consider this problem to be the most important open problem in computer science. It is one of the seven selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.

For instance, if you have a problem, and someone says "The answer to your problem is the set of numbers 1, 2, 3, 4, 5", a computer may be able, quickly, to figure out if the answer is right or wrong, but it may take a very long time for the computer to actually come up with "1, 2, 3, 4, 5" on its own. For some interesting, practical questions of this kind, we lack any way to find an answer quickly, but if we are provided an answer, it is possible to check—that is, to verify—the answer quickly. In this way, NP problems may be thought of as being like riddles: it may be hard to come up with the answer to a riddle, but once one hears the answer, the answer seems obvious. In this comparison (analogy), the basic question is: are riddles really as hard as we think they are, or are we missing something?

Because these kinds of "P versus NP" questions are so practically important, many mathematicians, scientists, and computer programmers want to prove the general proposition, that every quickly-checked problem can also be solved quickly. This question is important enough that the Clay Mathematical Institute will give $1,000,000 to anyone who successfully provides a proof. 

Digging a little deeper, we see that all P problems are NP problems: it is easy to check that a solution is correct by solving the problem and comparing the two solutions. However, people want to know about the opposite: Are there any NP problems other than P problems, or are all NP problems just P problems? If NP problems are really not the same as P problems (P ≠ NP), it would mean that no general, fast ways to solve those NP problems can exist, no matter how hard we look. However if all NP problems are P problems (P = NP), it would mean that new, very fast problem-solving methods do exist. We just have not found them yet.

Since the best efforts of scientists and mathematicians have not found general, easy methods for solving NP problems yet, many people believe that there are NP problems other than P problems (that is, that P ≠ NP is true). Most mathematicians also believe this to be true, but currently no one has proven it by rigorous mathematical analysis. If it can be proven that NP and P are the same (P = NP is true), it would have a huge impact on many aspects of day-to-day life. For this reason, the question of "P versus NP" is an important and widely studied topic.

Suppose someone wants to build two towers, by stacking rocks of different mass. One wants to make sure that each of the towers has exactly the same mass. That means one will have to put the rocks into two piles that have the same mass. If one guesses a division of the rocks that one thinks will work, it would be easy for one to check if one was right. (To check the answer, one can divide the rocks into two piles, then use a balance to see if they have the same mass.) Because it is easy to check this problem, called 'Partition' by computer scientists—easier than to solve it outright, as we will see—it is an NP problem.

How hard is it to solve, outright? If one starts with just 100 rocks, there are formula_1, or about formula_2 possible ways (combinations) to divide these rocks into two piles. If one could check one unique combination of rocks every day, it would take formula_3 years of effort. For comparison, physicists believe that the universe is about formula_4 years old formula_5 or about formula_6 secondsformula_7, or about one trillionth as old as the time it would take for our rock piling effort. That means that if one takes all of the time that has passed since the beginning of the universe, one would need to check more than two trillion formula_8 different ways of dividing the rocks (combinations) "every second", in order to check all of the different ways.

If one programmed a powerful computer, to test all of these ways to divide the rocks, one might be able to check formula_9 combinations per second using current systems. This means one would still need formula_10 very powerful computers, "working since the origin of the universe," to test all the ways of dividing the rocks. 

However, it may be possible to find a method of dividing the rocks into two equal piles without checking all combinations. The question "Is P equal to NP?" is a shorthand for asking if any method like that can exist.

There are many important NP problems that people don't know how to solve in a way that is faster than testing every possible answer. Here are some examples:






In the example above, we see that with formula_11 rocks, there are formula_12 ways to partition the set of rocks. With formula_13 rocks, there are formula_14 combinations. The function formula_15 is an exponential function. It's important to NP because it models the worst-case number of computations that are needed to solve a problem and, thus, the worst-case amount of time required.

And so far, for the hard problems, the solutions have required on the order of formula_14 computations. For any particular problem, people have found ways to reduce the number of computations needed. One might figure out that a way to do just 1% of the worst-case number of computation and that saves a "lot" of computing, but that is still formula_17 computations. And every extra rock still doubles the number of computations needed to solve the problem. There are insights that can produce methods to do even fewer computations producing variations of the model: e.g. formula_18. But the exponential function still dominates as formula_13 grows.

Consider the problem of scheduling exams (described above). But suppose, next, that there are 15000 students. There's a computer program that takes the schedules of all 15000 students. It runs in an hour and outputs an exam schedule so that all students can do their exams in one week. It satisfies lots of rules (no back-to-back exams, no more than 2 exams in any 28 hour period, ...) to limit the stress of exam week. The program runs for one hour at mid-term break and everyone knows his/her exam schedule with plenty of time to prepare.

The next year, though, there are 10 more students. If the same program runs on the same computer then that one hour is going to turn into formula_20 hours, because every additional student doubles the computations. That's formula_21 weeks! If there were 20 more students, then

Thus, for formula_26 students, it takes one hour. For formula_27 students, it takes formula_25 years.

As you can see, exponential functions grow really fast. Most mathematicians believe that the hardest NP problems require exponential time to solve.

Mathematicians can show that there are some NP problems that are NP-Complete. An NP-Complete problem is at least as difficult to solve as any other NP problem. This means that if someone found a method to solve any NP-Complete problem quickly, they could use that same method to solve "every" NP problem quickly. All of the problems listed above are NP-Complete, so if the salesman found a way to plan his trip quickly, he could tell the teacher, and she could use that same method to schedule the exams. The farmer could use the same method to determine how many boxes she needs, and the woman could use the same method to find a way to build her towers.

Because a method that quickly solves one of these problems can solve them all, there are many people who want to find one. However, because there are so many different NP-Complete problems and nobody so far has found a way to solve even one of them quickly, most experts believe that solving NP-Complete problems quickly is not possible.

In computational complexity theory, the complexity class NP-complete (abbreviated NP-C or NPC), is a class of problems having two properties:

NP-complete is a subset of NP, the set of all decision problems whose solutions can be verified in polynomial time; NP may be equivalently defined as the set of decision problems solved in polynomial time on a machine. A problem p in NP is also in NPC if and only if every other problem in NP is transformed into p in polynomial time. NP-complete was to be used as an adjective: problems in the class NP-complete were as NP+complete problems.

NP-complete problems are studied because the ability to quickly verify solutions to a problem (NP) seems to correlate with the ability to quickly solve problem (P). It is found every problem in NP is quickly solved—as called the P = NP: problem set. The single problem in NP-complete is solved quickly, faster than every problem in NP also quickly solved, because the definition of an NP-complete problem states every problem in NP must be quickly reducible to every problem in NP-complete (it is reduced in polynomial time). 

The Boolean satisfiability problem is known to be NP complete. In 1972, Richard Karp formulated 21 problems that are known to be NP-complete. These are known as Karp's 21 NP-complete problems. They include problems such as the Integer programming problem, which applies linear programming techniques to the integers, the knapsack problem, or the vertex cover problem.


