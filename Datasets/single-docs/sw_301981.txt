Operant conditioning

Operant conditioning is a form of learning. In it, an individual changes its behaviour because of the consequences (results) of the behaviour. 

The person or animal learns its behaviour has a consequence. That consequence may be

There are four different contexts in operant conditioning. Here, the terms 'positive' and 'negative' are not used in their basic sense; "positive" means that something is added, and negative means something is taken away:

The idea of operant conditioning was first discovered by Edward Thorndike, and analyzed by B.F. Skinner. 

Operant conditioning is different from Pavlov's classical conditioning. Operant conditioning deals with the voluntary modification of behaviour; classical conditioning with training a reflex.

Operant conditioning, sometimes called "instrumental learning", was first studied by Edward L. Thorndike (1874–1949). He observed the behavior of cats trying to escape from home-made puzzle boxes. When first put in the boxes, cats took a long time to escape. With experience, successful responses occurred more frequently, enabling the cats to escape in less time. In his law of effect, Thorndike theorized that behaviours followed by satisfying consequences tend to be repeated, and those that produce unpleasant consequences are less likely to be repeated. In short, some consequences "strengthened" behavior and some consequences "weakened" behavior. Thorndike produced the first known learning curves by this procedure. 

B.F. Skinner (1904–1990) worked out a more detailed analysis of operant conditioning. Skinner invented the "operant conditioning chamber" which let him measure rate of response as a key dependent variable. He used a record of lever presses or key pecks.

Principles of operant conditioning: 


