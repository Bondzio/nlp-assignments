Law of large numbers

The law of large numbers (LLN) is a theorem from statistics. Consider some process in which random outcomes occur. For example, a random variable is repeatedly observed. Then the average of the observed values will be stable, in the long run. This means that in the long run, the average of the observed values will get ever closer to the expected value.

When rolling dice, the numbers 1, 2, 3, 4, 5 and 6 are possible outcomes. They are all equally likely. The population mean (or "expected value") of the outcomes is:

The following graph shows the results of an experiment of rolls of a die. In this experiment it can be seen that the average of die rolls varies wildly at first. As predicted by the LLN, the average stabilizes around the expected value of 3.5 as the number of observations become large.

Jakob Bernoulli first described the LLN. He says it was so simple that even the stupidest man instinctively knows it is true. Despite this, it took him over 20 years to develop a good mathematical proof. Once he had found it, he published the proof in "Ars Conjectandi" (The Art of Conjecturing) in 1713. He named this his "Golden Theorem". It became generally known as "Bernoulli's Theorem" (not to be confused with the Law in Physics with the same name.) In 1835, S.D. Poisson further described it under the name "La loi des grands nombres" (The law of large numbers). Thereafter, it was known under both names, but the "Law of large numbers" is most frequently used.

Other mathematicians also contributed to make the law better. Some of them were Chebyshev, Markov, Borel, Cantelli and Kolmogorov. After these studies there are now two different forms of the law: One is called the "weak" law and the other the "strong" law. These forms do not describe different laws. They have different ways to describe the convergence of the observed or measured probability to the actual probability. The strong form of the law implies the weak one.


