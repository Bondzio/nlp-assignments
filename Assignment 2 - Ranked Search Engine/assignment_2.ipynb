{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 471  995  184 ...,    3 1395 1266]\n",
      "0.2184184447109622\n",
      "0.218418444711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import numpy as np\n",
    "from ml_metrics import mapk , apk\n",
    "import re\n",
    "\n",
    "#Read all document files\n",
    "docs = []\n",
    "with open('../Datasets/cran/original/cran.all.1400') as f:\n",
    "    docs = re.split(\"\\.I [0-9]*\\n\",f.read())\n",
    "docs.pop(0)\n",
    "#print(len(docs))\n",
    "temp1_docs = []\n",
    "for doc in docs:\n",
    "    temp1_docs.append(re.sub(\"\\.T(.|\\n)*\\.W\\n\",\"\",doc))\n",
    "docs = temp1_docs\n",
    "\n",
    "#temp2_docs = []\n",
    "#for doc in docs:\n",
    "#    temp2_docs.append(re.sub(\"\\n\",\"\",doc))\n",
    "#docs = temp2_docs\n",
    "#print(docs)\n",
    "            \n",
    "#Transform all documents to TF-IDF            \n",
    "vv = TfidfVectorizer()            \n",
    "vv.fit(docs)\n",
    "transformed = vv.transform(docs)\n",
    "#print(transformed.shape)\n",
    "#print(transformed.toarray()) \n",
    "\n",
    "#Read all queries\n",
    "queries = []\n",
    "with open('../Datasets/cran/original/cran.qry') as f:\n",
    "    queries = re.split(\"\\.I [0-9]*\\n\\.W\\n\",f.read())\n",
    "queries.pop(0)\n",
    "#print(len(queries))\n",
    "#temp_queries = []\n",
    "#for query in queries:\n",
    "#    temp_queries.append(re.sub(\"\\n\",\"\",query))\n",
    "#queries = temp_queries\n",
    "#print(queries)\n",
    "\n",
    "#Transform all queries (using the same vectorizer) using TF-IDF\n",
    "t_queries = vv.transform(queries)\n",
    "#print(t_queries)\n",
    "\n",
    "#Compute cosine similarity between all pairs of (query, document)\n",
    "sims = 1-cdist(t_queries.toarray(), transformed.toarray(), metric='cosine')\n",
    "#print(sims)\n",
    "\n",
    "#Return a ranked list of relevant documents for each query\n",
    "ranked_lists=[]\n",
    "for sim in sims:\n",
    "    ranked_lists.append(np.argsort(sim)[::-1])\n",
    "    \n",
    "#add one to all indices\n",
    "for i in range(len(ranked_lists)):\n",
    "    ranked_lists[i] +=1\n",
    "print(ranked_lists[0])\n",
    "\n",
    "#read the cranqrel file\n",
    "refs = []\n",
    "with open('../Datasets/cran/cranqrel') as f:\n",
    "    refs = f.readlines()\n",
    "\n",
    "#split each line over spaces\n",
    "for j in range(len(refs)):\n",
    "    refs[j] = refs[j].split()\n",
    "\n",
    "#convert into integers\n",
    "for ref in refs:\n",
    "    for k in range(len(ref)):\n",
    "        ref[k] = int(ref[k])\n",
    "\n",
    "#remove relevance score\n",
    "for x in range(len(refs)):\n",
    "    refs[x] = refs[x][:-1]\n",
    "\n",
    "#create a reference dictionary\n",
    "refs_dic={}\n",
    "for y in range(1,226):\n",
    "    refs_dic[y] = []\n",
    "    for ref in refs:\n",
    "        if ref[0] == y:\n",
    "            refs_dic[y].append(ref[1])\n",
    "    \n",
    "#print(refs_dic)\n",
    "\n",
    "#generate lists of lists of rel docs for each query\n",
    "all_rel_docs = []\n",
    "for key in refs_dic:\n",
    "    all_rel_docs.append(refs_dic[key])\n",
    "\n",
    "#manual ap\n",
    "def manual_ap(ref, res):\n",
    "    \n",
    "    sum_so_far = 0\n",
    "    rel_so_far = 0\n",
    "    for index,element in enumerate(res):\n",
    "        rank = index + 1\n",
    "        if element in ref:\n",
    "            rel_so_far = rel_so_far + 1\n",
    "            temp = rel_so_far/rank\n",
    "            sum_so_far = sum_so_far + temp\n",
    "    ap = sum_so_far/len(ref)        \n",
    "    \n",
    "    return(ap)\n",
    "\n",
    "#test manual_ap\n",
    "#print(manual_ap(all_rel_docs[0],ranked_lists[0]))\n",
    "#print(apk(all_rel_docs[0], ranked_lists[0], len(ranked_lists[0])))\n",
    "\n",
    "#calculate map manually\n",
    "summation = 0\n",
    "for a in range(225):\n",
    "    summation=summation+(manual_ap(all_rel_docs[a],ranked_lists[a]))\n",
    "\n",
    "my_map = summation/len(ranked_lists)\n",
    "\n",
    "print(my_map)\n",
    "    \n",
    "#using ml_metrics\n",
    "print(mapk(all_rel_docs, ranked_lists, max([len(res) for res in ranked_lists])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
